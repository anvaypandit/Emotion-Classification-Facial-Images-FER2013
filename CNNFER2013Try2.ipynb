{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNFER2013Try2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "figbXnZ-rnyH",
        "colab_type": "code",
        "outputId": "b28ca0e5-71e5-4127-9d33-b0f63493c660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Keras==2.2.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Keras==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 29.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0) (1.16.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0) (1.2.1)\n",
            "Collecting keras-applications==1.0.2 (from Keras==2.2.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0) (2.8.0)\n",
            "Collecting keras-preprocessing==1.0.1 (from Keras==2.2.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
            "\u001b[31mtensorflow 1.13.1 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.13.1 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, keras-preprocessing, Keras\n",
            "  Found existing installation: Keras-Applications 1.0.7\n",
            "    Uninstalling Keras-Applications-1.0.7:\n",
            "      Successfully uninstalled Keras-Applications-1.0.7\n",
            "  Found existing installation: Keras-Preprocessing 1.0.9\n",
            "    Uninstalling Keras-Preprocessing-1.0.9:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.9\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed Keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8YtCtj4FpNiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "af2357bd-1c23-4fc9-fc74-5a7a51282450"
      },
      "cell_type": "code",
      "source": [
        "!pip install keras_vggface"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/11/9c/d249cf4998344806d71b0351db690917413d1f7eaab83805f4095375e7a1/keras_vggface-0.5.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.16.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (4.3.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.13.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras_vggface) (0.46)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (0.2.2)\n",
            "Collecting keras-applications>=1.0.6 (from tensorflow->keras_vggface)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 30.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (1.13.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras_vggface) (0.33.1)\n",
            "Collecting keras-preprocessing>=1.0.5 (from tensorflow->keras_vggface)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow->keras_vggface) (40.9.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->keras_vggface) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->keras_vggface) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->keras_vggface) (3.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->keras_vggface) (5.1.3)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/72/aa/01/eb7baeb2f6e2d2f0d2aabddb5f01d57fa22fbd019ee2799bf5\n",
            "Successfully built keras-vggface\n",
            "\u001b[31mkeras 2.2.0 has requirement keras-applications==1.0.2, but you'll have keras-applications 1.0.7 which is incompatible.\u001b[0m\n",
            "\u001b[31mkeras 2.2.0 has requirement keras-preprocessing==1.0.1, but you'll have keras-preprocessing 1.0.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-vggface, keras-applications, keras-preprocessing\n",
            "  Found existing installation: Keras-Applications 1.0.2\n",
            "    Uninstalling Keras-Applications-1.0.2:\n",
            "      Successfully uninstalled Keras-Applications-1.0.2\n",
            "  Found existing installation: Keras-Preprocessing 1.0.1\n",
            "    Uninstalling Keras-Preprocessing-1.0.1:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.1\n",
            "Successfully installed keras-applications-1.0.7 keras-preprocessing-1.0.9 keras-vggface-0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras_applications",
                  "keras_preprocessing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ni9bdDrIpXzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "546459ba-3d50-4168-c9f9-18b15ea878ed"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/anvaypandit/Emotion-Classification-Facial-Images-FER2013.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Emotion-Classification-Facial-Images-FER2013'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 23 (delta 5), reused 19 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r9vuU7mcyAaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7b03b10-c8ee-4142-8940-eaf747235f35"
      },
      "cell_type": "code",
      "source": [
        "cd Emotion-Classification-Facial-Images-FER2013/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotion-Classification-Facial-Images-FER2013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DQVbAMSTqUl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b666962-90f6-42d1-f4e5-c29cad3174c1"
      },
      "cell_type": "code",
      "source": [
        "# Upload the excel data train.csv,test.csv,val.csv in data folder\n",
        "!python image_preprocessor.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N6by3_UQzEw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mkdir Try2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5fkXB-u2roYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.python.lib.io import file_io\n",
        "from skimage.transform import resize\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam,SGD\n",
        "from keras.callbacks import TensorBoard, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, Callback,ModelCheckpoint\n",
        "import h5py # For saving the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmyVvCReruea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PARAMETERS ##########################################################################################################################################\n",
        "\n",
        "# Folder where logs and models are stored\n",
        "folder = 'ResNet-50'\n",
        "\n",
        "# Size of the images\n",
        "img_height, img_width = 197,197\n",
        "\n",
        "# Parameters\n",
        "num_classes         = 7     # ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n",
        "epochs_top_layers   = 5\n",
        "epochs_all_layers   = 100\n",
        "batch_size          = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clm3a0Bvwjdp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "Xh94TO-Vr0-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Folder where logs and models are stored\n",
        "folder = 'gs://emotion_recognition/logs/ResNet-50'\n",
        "\n",
        "# Data paths\n",
        "train_dataset\t= 'gs://emotion_recognition/FER-2013/fer2013_train.csv'\n",
        "eval_dataset \t= 'gs://emotion_recognition/FER-2013/fer2013_eval.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4OSoNWMsO-o",
        "colab_type": "code",
        "outputId": "bf9aad95-2fd8-4e15-cc7d-54fcf09f0f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "# MODEL ###############################################################################################################################################\n",
        "\n",
        "# Create the based on ResNet-50 architecture pre-trained model\n",
        "    # model:        Selects one of the available architectures vgg16, resnet50 or senet50\n",
        "    # include_top:  Whether to include the fully-connected layer at the top of the network\n",
        "    # weights:      Pre-training on VGGFace\n",
        "    # input_shape:  Optional shape tuple, only to be specified if include_top is False (otherwise the input\n",
        "    #               shape has to be (224, 224, 3) (with 'channels_last' data format) or (3, 224, 224) (with\n",
        "    #               'channels_first' data format). It should have exactly 3 inputs channels, and width and\n",
        "    #               height should be no smaller than 197. E.g. (200, 200, 3) would be one valid value.\n",
        "# Returns a keras Model instance\n",
        "base_model = VGGFace(\n",
        "    model       = 'resnet50',\n",
        "    include_top = False,\n",
        "    weights     = 'vggface',\n",
        "    input_shape = (img_height,img_width,3))\n",
        "\n",
        "# Places x as the output of the pre-trained model\n",
        "x = base_model.output\n",
        "\n",
        "# Flattens the input. Does not affect the batch size\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Add a fully-connected layer and a logistic layer\n",
        "# Dense implements the operation: output = activation(dot(input, kernel) + bias(only applicable if use_bias is True))\n",
        "    # units:        Positive integer, dimensionality of the output space\n",
        "    # activation:   Activation function to use\n",
        "    # input shape:  nD tensor with shape: (batch_size, ..., input_dim)\n",
        "    # output shape: nD tensor with shape: (batch_size, ..., units)\n",
        "\n",
        "#x = Dense(1024, activation = 'relu')(x)\n",
        "x = Dense(1024, activation = 'relu')(x)\n",
        "predictions = Dense(num_classes, activation = 'softmax')(x)\n",
        "\n",
        "# The model we will train\n",
        "model = Model(inputs = base_model.input, outputs = predictions)\n",
        "# model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j_gZk4_KwmLQ",
        "colab_type": "code",
        "outputId": "83df80d1-2b13-42cb-c8fd-85cec74f7baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    samplewise_center=True,  # set each sample mean to 0\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    shear_range=10, # 10 degrees\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='reflect',\n",
        "    rescale=(1/255.),\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    data_format='channels_last',\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    samplewise_center=True,  # set each sample mean to 0\n",
        "    rescale=(1/255.),\n",
        "    data_format='channels_last')\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/Train',\n",
        "        target_size=(197,197),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'data/Valid',\n",
        "        target_size=(197,197),\n",
        "        batch_size = batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 3589 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tNndJI09zi3z",
        "colab_type": "code",
        "outputId": "7c31380a-d717-4080-81c9-e6eae12423ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "# UPPER LAYERS TRAINING ###############################################################################################################################\n",
        "\n",
        "# First: train only the top layers (which were randomly initialized) freezing all convolutional ResNet-50 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile (configures the model for training) the model (should be done *AFTER* setting layers to non-trainable)\n",
        "    # optimizer:    String (name of optimizer) or optimizer object\n",
        "        # lr:       Float >= 0. Learning rate\n",
        "        # beta_1:   Float, 0 < beta < 1. Generally close to 1\n",
        "        # beta_2:   Float, 0 < beta < 1. Generally close to 1\n",
        "        # epsilon:  Float >= 0. Fuzz factor\n",
        "        # decay:    Float >= 0. Learning rate decay over each update\n",
        "    # loss:     String (name of objective function) or objective function\n",
        "    # metrics:  List of metrics to be evaluated by the model during training and testing\n",
        "model.compile(\n",
        "    optimizer   = Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0), \n",
        "    loss        = 'categorical_crossentropy', \n",
        "    metrics     = ['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model on the new data for a few epochs (Fits the model on data yielded batch-by-batch by a Python generator)\n",
        "    # generator:        A generator or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing\n",
        "    #                   The output of the generator must be either {a tuple (inputs, targets)} {a tuple (inputs, targets, sample_weights)}\n",
        "    # steps_per_epoch:  Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch\n",
        "    #                   It should typically be equal to the number of unique samples of your dataset divided by the batch size \n",
        "    # epochs:           Integer, total number of iterations on the data\n",
        "    # validation_data:  This can be either {a generator for the validation data } {a tuple (inputs, targets)} {a tuple (inputs, targets, sample_weights)}\n",
        "\n",
        "model.fit_generator(\n",
        "    generator           = train_generator,\n",
        "    steps_per_epoch     = 28709 //batch_size,  # samples_per_epoch / batch_size\n",
        "    epochs              = epochs_top_layers, \n",
        "    validation_steps    = 3589//batch_size,\n",
        "    validation_data     = validation_generator)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            "224/224 [==============================] - 250s 1s/step - loss: 7.8074 - acc: 0.2966 - val_loss: 4.8441 - val_acc: 0.1381\n",
            "Epoch 2/5\n",
            "224/224 [==============================] - 238s 1s/step - loss: 1.7688 - acc: 0.5180 - val_loss: 1.9288 - val_acc: 0.1849\n",
            "Epoch 3/5\n",
            "224/224 [==============================] - 236s 1s/step - loss: 1.0482 - acc: 0.6116 - val_loss: 2.1169 - val_acc: 0.1728\n",
            "Epoch 4/5\n",
            "224/224 [==============================] - 236s 1s/step - loss: 0.9537 - acc: 0.6472 - val_loss: 1.9054 - val_acc: 0.1835\n",
            "Epoch 5/5\n",
            "224/224 [==============================] - 238s 1s/step - loss: 0.8749 - acc: 0.6772 - val_loss: 1.9704 - val_acc: 0.1786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa27b8d1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "bnfp91Io2AmF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FULL NETWORK TRAINING ###############################################################################################################################\n",
        "\n",
        "# At this point, the top layers are well trained and we can start fine-tuning convolutional layers from ResNet-50\n",
        "\n",
        "# Fine-tuning of all the layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# We need to recompile the model for these modifications to take effect (we use SGD with nesterov momentum and a low learning rate)\n",
        "    # optimizer:    String (name of optimizer) or optimizer object\n",
        "        # lr:       float >= 0. Learning rate\n",
        "        # momentum: float >= 0. Parameter updates momentum\n",
        "        # decay:    float >= 0. Learning rate decay over each update\n",
        "        # nesterov: boolean. Whether to apply Nesterov momentum\n",
        "    # loss:     String (name of objective function) or objective function\n",
        "    # metrics:  List of metrics to be evaluated by the model during training and testing\n",
        "model.compile(\n",
        "    optimizer   = SGD(lr = 1e-4, momentum = 0.9, decay = 0.0, nesterov = True),\n",
        "    loss        = 'categorical_crossentropy', \n",
        "    metrics     = ['accuracy'])\n",
        "\n",
        "\n",
        "def scheduler(epoch):\n",
        "    updated_lr = K.get_value(model.optimizer.lr) * 0.5\n",
        "    if (epoch % 19 == 0) and (epoch != 0):\n",
        "        K.set_value(model.optimizer.lr, updated_lr)\n",
        "        print(K.get_value(model.optimizer.lr))\n",
        "    return K.get_value(model.optimizer.lr)\n",
        "\n",
        "# Learning rate scheduler\n",
        "    # schedule: a function that takes an epoch index as input (integer, indexed from 0) and current learning\n",
        "    #           rate and returns a new learning rate as output (float)\n",
        "reduce_lr = LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "# Reduce learning rate when a metric has stopped improving\n",
        "\t# monitor: \tQuantity to be monitored\n",
        "\t# factor: \tFactor by which the learning rate will be reduced. new_lr = lr * factor\n",
        "\t# patience:\tNumber of epochs with no improvement after which learning rate will be reduced\n",
        "\t# mode: \tOne of {auto, min, max}\n",
        "\t# min_lr:\tLower bound on the learning rate\n",
        "reduce_lr_plateau = ReduceLROnPlateau(\n",
        "\tmonitor \t= 'val_loss',\n",
        "\tfactor\t\t= 0.5,\n",
        "\tpatience\t= 3,\n",
        "\tmode \t\t= 'auto',\n",
        "\tmin_lr\t\t= 1e-8)\n",
        "\n",
        "# Stop training when a monitored quantity has stopped improving\n",
        "# monitor:\t\tQuantity to be monitored\n",
        "\t# patience:\t\tNumber of epochs with no improvement after which training will be stopped\n",
        "\t# mode: \t\tOne of {auto, min, max}\n",
        "early_stop = EarlyStopping(\n",
        "\tmonitor \t= 'val_acc',\n",
        "\tpatience \t= 100,\n",
        "\tmode \t\t= 'auto')\n",
        "\n",
        "filepath='Try2/Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='auto',period=1)\n",
        "\n",
        "\t\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUnpWqUa9Cd8",
        "colab_type": "code",
        "outputId": "5162af11-89b9-4475-ffa0-4e1c7999d661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    generator           = train_generator,\n",
        "    steps_per_epoch     = 28709 // batch_size,  # samples_per_epoch / batch_size \n",
        "    epochs              = epochs_all_layers,                        \n",
        "    validation_data     = validation_generator,\n",
        "    validation_steps    = 3589//batch_size,\n",
        "    callbacks           = [reduce_lr, reduce_lr_plateau, early_stop, checkpointer])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "224/224 [==============================] - 323s 1s/step - loss: 0.3819 - acc: 0.8701 - val_loss: 0.9968 - val_acc: 0.6773\n",
            "\n",
            "Epoch 00001: saving model to Try2/Model.01-0.6773.hdf5\n",
            "Epoch 2/100\n",
            "224/224 [==============================] - 309s 1s/step - loss: 0.3759 - acc: 0.8742 - val_loss: 1.0153 - val_acc: 0.6797\n",
            "\n",
            "Epoch 00002: saving model to Try2/Model.02-0.6797.hdf5\n",
            "Epoch 3/100\n",
            " 72/224 [========>.....................] - ETA: 3:16 - loss: 0.3712 - acc: 0.8734"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1xxrInHesfnc",
        "colab_type": "code",
        "outputId": "a718236f-d907-41d5-f9d0-c4c103633a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/anvaypandit/Emotion-Classification-Facial-Images-FER2013.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Emotion-Classification-Facial-Images-FER2013'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 23 (delta 5), reused 19 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZQGkhqqKs9N1",
        "colab_type": "code",
        "outputId": "73896970-0ef4-465d-ef9b-18bb35f574e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cd Emotion-Classification-Facial-Images-FER2013/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotion-Classification-Facial-Images-FER2013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3GWDBHLHuhbX",
        "colab_type": "code",
        "outputId": "40b3548b-d54d-453e-9b91-b14e87201166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "cell_type": "code",
      "source": [
        "!python image_preprocessor.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Traceback (most recent call last):\n",
            "  File \"image_preprocessor.py\", line 39, in <module>\n",
            "    train_df,test_df,val_df= data_loader.load_all_data()\n",
            "  File \"/content/Emotion-Classification-Facial-Images-FER2013/data_loader.py\", line 31, in load_all_data\n",
            "    train_df = load_train_data()\n",
            "  File \"/content/Emotion-Classification-Facial-Images-FER2013/data_loader.py\", line 10, in load_train_data\n",
            "    train_df = pd.read_csv(train_fp)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 678, in parser_f\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 446, in _read\n",
            "    data = parser.read(nrows)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1036, in read\n",
            "    ret = self._engine.read(nrows)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1848, in read\n",
            "    data = self._reader.read(nrows)\n",
            "  File \"pandas/_libs/parsers.pyx\", line 876, in pandas._libs.parsers.TextReader.read\n",
            "  File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._read_low_memory\n",
            "  File \"pandas/_libs/parsers.pyx\", line 968, in pandas._libs.parsers.TextReader._read_rows\n",
            "  File \"pandas/_libs/parsers.pyx\", line 1094, in pandas._libs.parsers.TextReader._convert_column_data\n",
            "  File \"pandas/_libs/parsers.pyx\", line 1134, in pandas._libs.parsers.TextReader._convert_tokens\n",
            "  File \"pandas/_libs/parsers.pyx\", line 1180, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\", line 811, in is_integer_dtype\n",
            "    def is_integer_dtype(arr_or_dtype):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fpY7_A2zuleH",
        "colab_type": "code",
        "outputId": "0556f683-ea84-4701-b43c-838b34ce18d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "mkdir Try2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Try2’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7DzJtIhg3u-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}